# **EmoEye team Final Project page for Deep Learning**
This repository contains the code for the final project course on deep learning, which aims to build a multimodal architecture for emotion prediction problem. The goal of this project is to build and fine-tune multimodal neural network for prediction of Emotions based on Eye-Tracking and biometric data. The dataset itself is private and available upon request.

# **Dataset**
We used private dataset containing 29,153 5-second reactions from 160 participants to 799 Images. Images are very diverse and contain scenes, people, animals, etc.
After 5 seconds of Image presentation, participants reported the percieved emotion on Arousal (from 1 to 7, from boring to exciting) and Valence (from 1 to 7, from negative to positive) scales.
During 5 seconds of Image presentation the following data were collected:
1. The eye-tracking data - X, Y coordinates on the picture at which participant was looking at
2. The pupillometry data - sizes of the pupils
3. Galvanic Skin Response (GSR)
4. Heart Rate (HR)

## **Project presentation**
#### [Final project presentation](xxx)

# **General Project Goals**
Implement multimodal approach described in [this](https://dl.acm.org/doi/10.1145/3382507.3418828) article. Improve it by adding extra module processing shown visual stimuli.

# **Methods**
...
